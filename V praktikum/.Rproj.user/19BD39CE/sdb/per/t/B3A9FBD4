{
    "contents" : "#Eralda html koodis sinisena olev tekst muutujasse tekst. Kasuta paketti rvest.\nlibrary(rvest)\nhtml_source =\"http://andmeteadus.github.io/examples/html1.html\"\npage = html(html_source)\ntekst=page %>% \n    html_node(\"p#p01\") %>%\n    html_text()\n\n#Eralda html koodis punaselt olev tekst muutujasse tekst. Kasuta paketti rvest.\nhtml_source =\"http://andmeteadus.github.io/examples/html2.html\"\npage = html(html_source)\ntekst=page %>% \n    html_nodes(\"p.error\") %>%\n    html_text()\n\n#Eralda Riigikogu hääletamistulemuste veebilehe html lähtekoodist, mitu saadikut \n#hääletas kooseluseaduse eelnõu:\nhtml_source =\"http://www.riigikogu.ee/tegevus/tooulevaade/haaletused/haaletustulemused-kohalolekukontroll/a85129ed-4873-4b9d-ac37-4788b6587fa0/\"\npage = html(html_source)\ntekst=page %>% \n    html_nodes(\"li a span\") %>%\n    html_text()\n\nandmed=as.data.frame(tekst)\n#või\nsodi=page %>% \n    html_nodes(\"a span\") %>%\n    html_text()\n\n#Eralda kooseluseaduse eelnõu hääletamistulemuste veebilehe html lähtekoodist \n#andmetabel, kus on 101 rida ning tunnused nr, nimi, otsus, fraktsioon.\n# #\n# tabel=page %>% \n#     html_nodes(\"#koik\") %>%\n#     html_text()\n# #sellega saan nimed, kuid need on topelt\n# tekst2=page %>% \n#     html_nodes(\".w-1\") %>%\n#     html_text()\n# #siin on kogu tabel, kuid seda tuleb töödelda\n# tekst3=page %>% \n#     html_nodes(\"tr td\") %>%\n#     html_text()\n# \n# tekst4=page %>% \n#     html_nodes(\"td , .w-1\") %>%\n#     html_text()\n\n#sellega saab juba kätte\ntekst5=page %>% \n    html_nodes(\".table.table.table-striped.full-bars\") %>%\n    html_table()\n#siit saan data frame 101 liikme, erkonna ja hööletustulemusega, nr-d võtan\n#zipitud tabelitest, kuna vahepeal on kodulehte muudetud\nsub=tekst5[1]\nsub2=as.data.frame(sub)\n#puhastan otsuse poolt ja asendan tabelisse\njunn=gsub( \" \", \"\",sub2$Otsus)\njunn2=gsub( \"\\n\\n\", \"\",junn)\njunn3=gsub( \"^Poolt\", \"\",junn2)\njunn3=gsub( \"^Vastu\", \"\",junn3)\njunn3=gsub( \"^EiHääletanud\", \"\",junn3)\njunn3=gsub( \"^Puudub\", \"\",junn3)\njunn3=gsub( \"EiHääletanud\", \"Ei Hääletanud\",junn3)\nsub2$Otsus=junn3\n\n#Kirjuta vastav kood funktsiooniks extract_table (seda funktsiooni läheb vaja \n#järgmises ülesandes, kus eraldad kõigi Riigikogu XII hääletuste kohta vastava \n#tabeli). Sisendiks on kas veebilehe url, faili lokaalne asukoht või sõne. \n#Funktsioon peab tagastama vastava data.frame-i (pane tähele, et su funktsioon \n#ei tagastaks listi, milles on üks data.frame).\n#kuna kodukat on muudetud teen funktsiooni zipitud falide pealt (neid on vaja\n#massiga sisse lugeda)\n#Failis htmls.zip on olemas veebilehed kõigi Riigikogu XII hääletuste kohta. \n#Sinu ülesandeks on koostada andmetabel, kus ridades on Riigikogu saadiku \n#nimi ja veergudes kõik hääletamiskorrad. Seda andmestikku läheb \n#vaja järgmises praktikumis, kus uurime hääletamismustreid.\n#Kõigepealt paki lahti zip fail ning loe R-i sisse kõigi html failide nimed.\n#Näpunäide: Järgnev kood aitab kätte saada kõigi antud kaustas olevad \n#csv-failide nimed (seejuures argument full.names võimaldab tagastada terve \n#failitee).\nfilenames =list.files(\"./data/data\", pattern = \"*.html\", full.names=TRUE)\n\n#Esialgu loe sisse umbes 5 erinevat html faili.\n#NB! Alles siis, kui oled täiesti kindel, et sinu kood töötab korrektselt, \n#võta kasutusele kõik html failid.Näpunäide: Järgnev kood loeb sisse kõik \n#muutujas filenames olevad csv andmestikud ning tekitab neist listi.\nlist_of_dataframes = list()\nfor(i in 1:length(filenames)){\n    temp = read.csv(filenames[i])\n    list_of_dataframes[[i]] = temp\n}\n\n#Praegu pole sul read.csv käsuga midagi peale hakata, sest tegeleme html \n#failidega. Kasuta ülesandes 4 kirjutatud funktsiooni extract_table.\n#Eelneva for-tsükli asemel võid kasutada funktsiooni lapply.\n#Lisa igal tsükli sammul andmestikule hääletuse indeks või muu identifikaator. \n#Näiteks temp$haaletus = i.\n#teen siis kõigepealt funktsiooni\nlibrary(rvest)\nextract_table=function(url) {\n    html_source =url\n    page = html(html_source)\n    tabel=page %>% \n        html_nodes(\"table.List\") %>%\n        html_table()%>%\n        as.data.frame()\n    tabel\n}\n#proovin viie tabeli peal\nfilenames =list.files(\"./data/data\",pattern = \"*.html\",  full.names=TRUE)\n\nlist_of_dataframes = list()\nfor(i in 1:5){\n    temp = extract_table(filenames[i])\n    temp$haaletus = i\n    list_of_dataframes[[i]] = temp\n}\n\n#töötab, loen kõik sisse\nfilenames =list.files(\"./data/data\", pattern = \"*.html\", full.names=TRUE)\n\nlist_of_dataframes = list()\nfor(i in 1:length(filenames)){\n    temp = extract_table(filenames[i])\n    temp$haaletus = i\n    list_of_dataframes[[i]] = temp\n}\n\n#Nüüdseks peaksid olema saanud listi, mille elementideks on erinevad \n#andmetabelid (kõiki faile kasutades peaks nende koguarv olema 1845). Tee \n#nendest andmetabelitest üks suur (pikk) andmetabel, paigutades need üksteise \n#otsa. Seda aitab teha paketi dplyr funktsioon rbind_all. Tulemuseks peaksid \n#saama andmetabeli, mille ridade arv on 101 * “sinu kasutatud failide arv”.\nlibrary(dplyr)\nandmed=rbind_all(list_of_dataframes)\n\n#Muuda pikk andmetabel laiaks. Seda aitab teha paketi reshape2 käsk dcast. \nlibrary(reshape2)\nandmed_lai=dcast(andmed, Nimi~haaletus, value.var = \"Otsus\")\n\nsave(andmed_lai, file=\"riigikogu.RData\")\n#Lõpptulemuseks võiksid saada järgneva andmestiku, kus on 143 rida ning \n#1846 veergu. Klapib\n\n#Teine osa\n#Tagasta kõik Postimehe esilehe uudiste pealkirjad (joonisel näidatud kollasega).\n#Ära kurvasta, kui sa ei saa absoluutselt kõiki pealkirju, 97% on praegu piisav.\n#Kui sulle ei meeldi Postimehe veebilehe hiiglaslikku lähtekoodi inspekteerida \n#brauseris vaikimisi olevate vahenditega, siis abiks on praktikumis tutvustatud \n#tööriist selectorgadget.Vaata, et sinu tagastatud pealkirjade hulgas poleks \n#tühju sõnesid või arve.\nurl=\"http://www.postimees.ee/\"\npage = html(url)\ntekst=page %>% \n    html_nodes(\".frontHeading\") %>%\n    html_text()\n#puhastame\ntekst_puhas=gsub(\"\\n\", \"\", tekst)\n#palkirjade lõppu korjab ka kommentaaride arvu, puhastame need välja\ntekst_puhas=gsub(\"\\\\d*$\", \"\", tekst_puhas)\n#eemaldame tühjad stringid\ntekst_puhas=tekst_puhas[tekst_puhas != \"\"] \n\n\n#Eva “Usin” Masinal on suur huvi ilmaandmete vastu. Kümme minutit pärast iga \n#täistundi märgib ta Ilmateenistuse vaatlusandmeid oma märkmikku, et hiljem \n#analüüsi teha. Automatiseeri seesama protsess. Juhised:\n#Riigi Ilmateenistus pakub värskeid ilmaandmeid XML faili kujul. Meie tegeleme \n#Eesti vaatlusandmete XML failiga. Saa XML failist kätte iga ilmajaama õhurõhk.\n#Saa XML failist kätte iga ilmajaama tuule kiirus.\n#Tee neist õhurõhu ja tuule kiiruse scatterplot.\nurl=\"http://www.ilmateenistus.ee/ilma_andmed/xml/observations.php\"\npage = html(url)\n\nohurohk=page %>% \n    html_nodes(\"airpressure\")%>%\n    html_text()\n\ntuulekiirus=page %>% \n    html_nodes(\"windspeed\") %>%\n    html_text()\n\n# ilm=page %>% \n#     html_nodes(\"name, airpressure, windspeed\")%>% \n#     html_text()\n\nnimi=page %>% \n    html_nodes(\"name\")%>%\n    html_text()\n\n#teeme numericuks\nohurohk=as.numeric(as.character(ohurohk))\ntuulekiirus=as.numeric(as.character(tuulekiirus))\nilm=data.frame(nimi, tuulekiirus, ohurohk)\n#teeme graafiku\nlibrary(ggplot2)\n\nggplot(ilm, aes(x=tuulekiirus, y=ohurohk))+\n    geom_point()\n\n#Eva “Usin” Masin on lotohuviline, aga ta pole aastaid Viking Lottoga võitnud. \n#Ta arvab, et lototulemused pole päris juhuslikud ning lotos on võimalik \n#statistiline eelis saada. Seepärast märgib ta iga lotokolmapäev Viking Lotto \n#loositud numbrid üles ja uurib, kas number kahtesid loositakse rohkem välja, \n#kui juhus lubaks.\n#Õpeta tehis-Eva tegema seda sama.\n#Eesti Loto veebilehel on toodud statistika loositud pallide sagedusest.\n#Eralda vastav tabel, kus veergudes on tunnused number, sagedus ja sagedus \n#protsentides.selectorgadget veab sind siin alt ning kergem on lähtekoodi \n#inspekteerida brauseris olevate tööriistadega (Chrome’s vajuta Ctrl + Shift + I \n#või tee parem klikk ja vajuta inspekteeri elementi). Visualiseeri saadud \n#andmetabelit. Tee näiteks tulpdiagramm, kus x-teljel on arvud 1-48 ning y-telg \n#tähistab sagedust.\nhtml_source =\"https://www.eestiloto.ee/osi/stats.do?lastDraws=250&gameCode=11&sort=frq0&action=searchNumbers\"\n#lingi osas tegin ise uue päringu ja võtsin siis lingi, algne peksis segast\npage = html(html_source)\nloto=page %>% \n    html_nodes(\"table\") %>%\n    html_table(fill=T)\n\nnumbrid=as.data.frame(loto[5])\n#graafik\nlibrary(ggplot2)\nggplot(numbrid, aes(x=factor(Number), y=Sagedus))+\n    geom_bar(stat=\"identity\")\n\n#(2 boonuspunkti + lisaboonuspunkt) Viimase 250 loosiga on pall 35 tulnud 28 \n#korral, pall 34 aga 59 korral. Uuri, kas on alust arvata, et Viking Lotto \n#süsteem on kallutatud. Selleks mõtle välja, kuidas seda kontrollida \n#(näiteks võid kasutada simulatsioonidel põhinevat lähenemist). Selgita \n#lühidalt oma lähenemist ja raporteeri, millise tulemuse said. Lisaboonuspunkti \n#saamiseks visualiseeri seda tulemust.\n#teen dataframe, kuhu hakkan itereerima\n# tulem=data.frame(c(1:250))\n# names(tulem)=\"järjekord\"\n# \n# for(i in 1:100) \n# { \n#     tulem[,i+1]=sample(1:48, 250, replace=T)\n#     names(tulem)[i+1] <- paste(\"iter\", i, sep = \"\")\n# }\n# \n# library(reshape2)\n# tulem_melt=melt(tulem, id=c(\"järjekord\"))\n# #arvutame iga iteratsioonis iga numbri sageduse\n# tulem_sagedus=data.frame(table(tulem_melt$value, tulem_melt$variable))\n# #hoiame alles ainult 34 ja 35 sagedused, kuna need huvitavad\n# tulem_vaja=subset(tulem_sagedus, Var1%in% c(34,35))\n# \n# ggplot(tulem_vaja, aes(x=Freq, colour=Var1))+\n#     geom_density()\n\n#siiski minu oma ei anna sama tulemust, pean itereerima ikka 8 numbri kaupa\nlibrary(reshape2)\ntulem=data.frame(c(1:8))\nnames(tulem)=\"järjekord\"\nlist34=list()\nlist35=list()\nj=1\nfor (j in 1:100)  {\n    \n    tulem=data.frame(c(1:8))\n    names(tulem)=\"järjekord\"\n    \n        for (i in 1:250) \n        { \n    tulem[,i+1]=sample(1:48, 8, replace=F)\n    names(tulem)[i+1] <- paste(\"iter\", i, sep = \"\")\n        }\n    \n    tulem_melt=melt(tulem, id=c(\"järjekord\"))\n    #arvutame iga iteratsioonis iga numbri sageduse\n    tulem_sagedus=data.frame(table(tulem_melt$value, tulem_melt$variable))\n    #hoiame alles ainult 34 ja 35 sagedused, kuna need huvitavad\n    tulem_vaja=subset(tulem_sagedus, Var1%in% c(34,35))\n    \n    list34[j]=sum(tulem_vaja$Freq[tulem_vaja[,1]==34])\n    list35[j]=sum(tulem_vaja$Freq[tulem_vaja[,1]==35])\n    j=j+1\n}\n\n#teeme dataframeiks listid ja numericuks et ggplottida\nsimulatsioonid=as.data.frame(rbind(list34, list35))\nsimulatsioonid=as.data.frame(t(simulatsioonid)) #transpose\nsimulatsioonid$list34=as.numeric(simulatsioonid$list34)\nsimulatsioonid$list35=as.numeric(simulatsioonid$list35)\nsimulatsioonid_melt=melt(simulatsioonid)\nsimulatsioonid_melt$value=as.numeric(simulatsioonid_melt$value)\n#sit on hästi näha, mis on 34 ja 35 esinemissageduste jaotus 250 numrbite\n#võtmise korral lotos\nggplot(simulatsioonid_melt, aes(x=variable, y=value))+\n    geom_boxplot()\n\n#Alusta suvaliselt veebilehelt. Eralda kõik väljuvad lingid. Vali üks neist \n#linkidest suvaliselt. Hüppa sellele lingile. Kui sellel leheküljel pole \n#ühtegi väljuvat linki, mine tagasi. Kui väljuvaid linke on mitmeid, vali \n#jälle välja suvaline ja hüppa sinna. Kui jõudsid Facebooki, on katse lõppenud. \n#Korda seda protsessi mitu korda ja erinevate alglehtedega. Uuri, mitmel juhul \n#jõudsid FBsse. Näpunäide: Abiks on paketi rvest funktsioon follow_link().\n\n\n\ns <- html_session(\"http://www.postimees.ee/\")\ns %>% \n    follow_link(sample(1:3, 1))%>%\n    follow_link(\"elu\")%>%\n    follow_link(\"face\")\n\n\ns <- html_session(\"http://had.co.nz\")\ns %>% jump_to(\"thesis/\")\ns %>% follow_link(\"vita\")\ns %>% follow_link(3)\ns %>% follow_link(\"vita\")\n\n\n#(1 boonuspunkt) Mis on olnud Tartu Ülikooli Facebooki lehe kõige populaarsem \n#postitus? Mis on olnud matemaatika-informaatikateaduskonna Facebooki lehe \n#kõige populaarsem postitus? (5 boonuspunkti :-)) Kasuta R-i, et uuendada \n#oma staatust tekstiga ‘Teen aine “Statistiline andmeteadus ja visualiseerimine” \n#kodutööd. Väga põnev! :-)’. Abiks on käsk updateStatus.\n#(3 boonuspunkti) Kui sulle ei meeldi Facebooki algoritm, mille põhjal \n#ta postitusi ja pilte uudisvoos järjestab, mõtle välja algoritm, mis selle \n#parandab. Implementeeri selle prototüüp (kasuks tuleb käsk getNewsfeed).\nlibrary(devtools)\ninstall_github(\"pablobarbera/Rfacebook/Rfacebook\")\nlibrary(Rfacebook)\n\nfb_oauth <- fbOAuth(app_id=\"687303151396669\", \n                    app_secret=\"7b256b7abcebbe38430fb44a5db08576\")\n\nsave(fb_oauth, file=\"fb_oauth\")\n\nload(\"fb_oauth\")\nme <- getUsers(\"me\",token=fb_oauth)\nmy_likes <- getLikes(user=\"me\", token=fb_oauth)\nupdateStatus(\"Statistics are used much like a drunk uses a lamppost: for support, not illumination\", token=fb_oauth)\n",
    "created" : 1431714496394.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1960707974",
    "id" : "B3A9FBD4",
    "lastKnownWriteTime" : 1431972910,
    "path" : "~/Minu asjad/Statistika, mudelid, excel/R/Andmeteadus_TU/V praktikum/praktikum5_veebi_kraapimine.R",
    "project_path" : "praktikum5_veebi_kraapimine.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}